{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# segGeo = pd.read_csv('/Users/rachelspinti/Documents/River_bifurcation/all_basins_unfiltered_workflow/Colorado_segGeo.csv')\n",
    "# rsegGeo = pd.read_csv('/Users/rachelspinti/Documents/River_bifurcation/all_basins_unfiltered_workflow/Red_segGeo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segGeo\n",
    "# rsegGeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining NABD and NID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp, pandas as pd, matplotlib as mpl\n",
    "from pathlib import Path\n",
    "gdrive = Path(\"/Volumes/GoogleDrive/My Drive/Condon_Research_Group/Research_Projects/Rachel/Research/Data/bifurcation_data_repo\") #where shapefiles/csv live \n",
    "# gdrive2 = Path(\"/Volumes/GoogleDrive/My Drive/Condon_Research_Group/Research_Projects/Jen_Dams/Matching\") #where shapefiles/csv live "
   ]
  },
  {
   "source": [
    "### Read in data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nabd_dams = gp.read_file(gdrive/\"nabd/nabd_fish_barriers_2012.shp\")  #read in NABD from Drive\n",
    "nabd_dams = nabd_dams.drop_duplicates(subset='NIDID', keep=\"first\")  #drop everything after first duplicate\n",
    "# nabd_dams[\"DamID\"] = range(len(nabd_dams.COMID))  #add DamID \n",
    "nabd_dams = pd.DataFrame(nabd_dams)\n",
    "nabd_dams = nabd_dams[['COMID', 'NIDID', 'Norm_stor', 'Max_stor','Year_compl', 'Purposes', 'geometry', 'Dam_name']]\n",
    "nid = pd.read_csv(gdrive/'other_dam_datasets/NID2019_U.csv', usecols=['NIDID', 'NORMAL_STORAGE', 'MAX_STORAGE', 'YEAR_COMPLETED', 'DAM_NAME', 'LATITUDE', 'LONGITUDE'])"
   ]
  },
  {
   "source": [
    "### Checking things out"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "51795 91457\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         DAM_NAME    NIDID   LONGITUDE  \\\n",
       "0                                     COOPER LAKE  AK00001 -149.823147   \n",
       "1                                       BLUE LAKE  AK00002 -135.191700   \n",
       "2                                    SALMON CREEK  AK00003 -134.403608   \n",
       "3                                     ANNEX CREEK  AK00004 -134.126578   \n",
       "4                                    CRYSTAL LAKE  AK00005 -132.845500   \n",
       "...                                           ...      ...         ...   \n",
       "91452                           SHELL CREEK NO. 2  WY02601 -107.413988   \n",
       "91453                         WASHAKIE DIKE NO. 1  WY02902 -109.006036   \n",
       "91454                         WASHAKIE DIKE NO. 2  WY02903 -109.011705   \n",
       "91455                         WASHAKIE DIKE NO. 3  WY02904 -109.014574   \n",
       "91456  SMITH RANCH - HIGHLAND SATELLITE NO. 2 DAM  WY83120 -105.574400   \n",
       "\n",
       "        LATITUDE  YEAR_COMPLETED  MAX_STORAGE  NORMAL_STORAGE  \n",
       "0      60.433708          1959.0     127600.0        112000.0  \n",
       "1      57.063300          1961.0     266000.0        266000.0  \n",
       "2      58.341850          1914.0      18000.0         12000.0  \n",
       "3      58.326939          1968.0      23400.0         23400.0  \n",
       "4      56.600000          1955.0       5800.0          5200.0  \n",
       "...          ...             ...          ...             ...  \n",
       "91452  44.516375          1957.0       1949.0          1949.0  \n",
       "91453  42.979746          1935.0      10300.0          7940.0  \n",
       "91454  42.979860          1935.0      10300.0          7940.0  \n",
       "91455  42.979238          1935.0      10300.0          7940.0  \n",
       "91456  43.101390          1979.0        472.0           321.0  \n",
       "\n",
       "[91457 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DAM_NAME</th>\n      <th>NIDID</th>\n      <th>LONGITUDE</th>\n      <th>LATITUDE</th>\n      <th>YEAR_COMPLETED</th>\n      <th>MAX_STORAGE</th>\n      <th>NORMAL_STORAGE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>COOPER LAKE</td>\n      <td>AK00001</td>\n      <td>-149.823147</td>\n      <td>60.433708</td>\n      <td>1959.0</td>\n      <td>127600.0</td>\n      <td>112000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BLUE LAKE</td>\n      <td>AK00002</td>\n      <td>-135.191700</td>\n      <td>57.063300</td>\n      <td>1961.0</td>\n      <td>266000.0</td>\n      <td>266000.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SALMON CREEK</td>\n      <td>AK00003</td>\n      <td>-134.403608</td>\n      <td>58.341850</td>\n      <td>1914.0</td>\n      <td>18000.0</td>\n      <td>12000.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ANNEX CREEK</td>\n      <td>AK00004</td>\n      <td>-134.126578</td>\n      <td>58.326939</td>\n      <td>1968.0</td>\n      <td>23400.0</td>\n      <td>23400.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CRYSTAL LAKE</td>\n      <td>AK00005</td>\n      <td>-132.845500</td>\n      <td>56.600000</td>\n      <td>1955.0</td>\n      <td>5800.0</td>\n      <td>5200.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>91452</th>\n      <td>SHELL CREEK NO. 2</td>\n      <td>WY02601</td>\n      <td>-107.413988</td>\n      <td>44.516375</td>\n      <td>1957.0</td>\n      <td>1949.0</td>\n      <td>1949.0</td>\n    </tr>\n    <tr>\n      <th>91453</th>\n      <td>WASHAKIE DIKE NO. 1</td>\n      <td>WY02902</td>\n      <td>-109.006036</td>\n      <td>42.979746</td>\n      <td>1935.0</td>\n      <td>10300.0</td>\n      <td>7940.0</td>\n    </tr>\n    <tr>\n      <th>91454</th>\n      <td>WASHAKIE DIKE NO. 2</td>\n      <td>WY02903</td>\n      <td>-109.011705</td>\n      <td>42.979860</td>\n      <td>1935.0</td>\n      <td>10300.0</td>\n      <td>7940.0</td>\n    </tr>\n    <tr>\n      <th>91455</th>\n      <td>WASHAKIE DIKE NO. 3</td>\n      <td>WY02904</td>\n      <td>-109.014574</td>\n      <td>42.979238</td>\n      <td>1935.0</td>\n      <td>10300.0</td>\n      <td>7940.0</td>\n    </tr>\n    <tr>\n      <th>91456</th>\n      <td>SMITH RANCH - HIGHLAND SATELLITE NO. 2 DAM</td>\n      <td>WY83120</td>\n      <td>-105.574400</td>\n      <td>43.101390</td>\n      <td>1979.0</td>\n      <td>472.0</td>\n      <td>321.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>91457 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "print(len(nabd_dams), len(nid))\n",
    "nabd_dams = nabd_dams.sort_values('NIDID')\n",
    "nabd_dams\n",
    "nid"
   ]
  },
  {
   "source": [
    "### Figuring out what is missing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "missing # 42648\nlarge missing # 171\n"
     ]
    }
   ],
   "source": [
    "#Merge on nabd\n",
    "# nabd_by_ID = nabd_dams.merge(nid, on = 'NIDID', how = 'inner')\n",
    "# nabd_by_ID\n",
    "\n",
    "#Merge on nid\n",
    "nid.NORMAL_STORAGE = nid.NORMAL_STORAGE * 1233.48   #convert units to cubic meters\n",
    "nid_by_ID = nid.merge(nabd_dams, on = 'NIDID', how = 'left')\n",
    "nid_by_ID['COMID'] = nid_by_ID['COMID'].fillna(0)\n",
    "missing = nid_by_ID[nid_by_ID['COMID'] ==0]\n",
    "print('missing #',len(missing))\n",
    "\n",
    "large_missing = missing[missing['NORMAL_STORAGE']>=10**8]  #is it 10^8 or 10^6?\n",
    "print('large missing #', len(large_missing))\n",
    "large_missing.to_csv('large_dams_missing.csv')"
   ]
  },
  {
   "source": [
    "## Spatially join NHD and NID"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowlines = gp.read_file(gdrive/\"nhd/NHDFlowlines.csv\",\n",
    "                                usecols=['Hydroseq', 'UpHydroseq', 'DnHydroseq',\n",
    "                                        'REACHCODE','LENGTHKM', 'COMID', 'WKT', 'QC_MA',\n",
    "                                        'StreamOrde'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'gp' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7d03245ba98a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnid_gdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLONGITUDE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLATITUDE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# nid_gdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gp' is not defined"
     ]
    }
   ],
   "source": [
    "nid_gdf = gp.GeoDataFrame(nid, geometry=gp.points_from_xy(nid.LONGITUDE, nid.LATITUDE))\n",
    "# nid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nid_nhd_join = gp.sjoin(nid_gdf, flowlines, how=\"left\", op='intersects')\n",
    "nid_nhd_join "
   ]
  },
  {
   "source": [
    "## Junk"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nid.NORMAL_STORAGE = nid.NORMAL_STORAGE * 1233.48   #convert units to MCM\n",
    "\n",
    "# for dam in range(len(nid)):\n",
    "#     missing = []\n",
    "#     grand_dams = []\n",
    "#     if nid.loc[dam, 'NIDID'] != nabd_dams.loc[dam, 'NIDID']:\n",
    "#         missing.append(nid.NIDID)\n",
    "#         if nid.loc[dam, 'NORMAL_STORAGE'] > 10**8:\n",
    "#             grand_dams.append(nid.NIDID)\n",
    "\n",
    "# print(len(missing), len(grand_dams))\n",
    "# missing\n",
    "\n",
    "#Trying to join by name\n",
    "# large_missing['DAM_NAME'] = large_missing['DAM_NAME'].str.title().str.strip()\n",
    "# nabd_dams['Dam_name'] = nabd_dams['Dam_name'].str.title().str.strip()\n",
    "# df['Region'] = df['Region'].str.title().str.strip()\n",
    "# nabd_dams\n",
    "# nid['DAM_NAME'] = nid['DAM_NAME'].str.title().str.strip()\n",
    "# nid = nid.rename(columns={'DAM_NAME':'Dam_name'})\n",
    "# by_name = nid.merge(nabd_dams, on = 'Dam_name', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = pd.read_csv('/Volumes/GoogleDrive/My Drive/Condon_Research_Group/Research_Projects/Rachel/Research/Data/bifurcation_data_repo/nhd/NHDFlowlines.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['WKT',\n",
       " 'OBJECTID',\n",
       " 'COMID',\n",
       " 'FDATE',\n",
       " 'RESOLUTION',\n",
       " 'GNIS_ID',\n",
       " 'GNIS_NAME',\n",
       " 'LENGTHKM',\n",
       " 'REACHCODE',\n",
       " 'FLOWDIR',\n",
       " 'WBAREACOMI',\n",
       " 'FTYPE',\n",
       " 'FCODE',\n",
       " 'Shape_Length',\n",
       " 'StreamLeve',\n",
       " 'StreamOrde',\n",
       " 'StreamCalc',\n",
       " 'FromNode',\n",
       " 'ToNode',\n",
       " 'Hydroseq',\n",
       " 'LevelPathI',\n",
       " 'Pathlength',\n",
       " 'TerminalPa',\n",
       " 'ArbolateSu',\n",
       " 'Divergence',\n",
       " 'StartFlag',\n",
       " 'TerminalFl',\n",
       " 'DnLevel',\n",
       " 'UpLevelPat',\n",
       " 'UpHydroseq',\n",
       " 'DnLevelPat',\n",
       " 'DnMinorHyd',\n",
       " 'DnDrainCou',\n",
       " 'DnHydroseq',\n",
       " 'FromMeas',\n",
       " 'ToMeas',\n",
       " 'RtnDiv',\n",
       " 'VPUIn',\n",
       " 'VPUOut',\n",
       " 'AreaSqKM',\n",
       " 'TotDASqKM',\n",
       " 'DivDASqKM',\n",
       " 'Tidal',\n",
       " 'TOTMA',\n",
       " 'WBAreaType',\n",
       " 'PathTimeMA',\n",
       " 'HWNodeSqKM',\n",
       " 'MAXELEVRAW',\n",
       " 'MINELEVRAW',\n",
       " 'MAXELEVSMO',\n",
       " 'MINELEVSMO',\n",
       " 'SLOPE',\n",
       " 'ELEVFIXED',\n",
       " 'HWTYPE',\n",
       " 'SLOPELENKM',\n",
       " 'QA_MA',\n",
       " 'VA_MA',\n",
       " 'QC_MA',\n",
       " 'VC_MA',\n",
       " 'QE_MA',\n",
       " 'VE_MA',\n",
       " 'QA_01',\n",
       " 'VA_01',\n",
       " 'QC_01',\n",
       " 'VC_01',\n",
       " 'QE_01',\n",
       " 'VE_01',\n",
       " 'QA_02',\n",
       " 'VA_02',\n",
       " 'QC_02',\n",
       " 'VC_02',\n",
       " 'QE_02',\n",
       " 'VE_02',\n",
       " 'QA_03',\n",
       " 'VA_03',\n",
       " 'QC_03',\n",
       " 'VC_03',\n",
       " 'QE_03',\n",
       " 'VE_03',\n",
       " 'QA_04',\n",
       " 'VA_04',\n",
       " 'QC_04',\n",
       " 'VC_04',\n",
       " 'QE_04',\n",
       " 'VE_04',\n",
       " 'QA_05',\n",
       " 'VA_05',\n",
       " 'QC_05',\n",
       " 'VC_05',\n",
       " 'QE_05',\n",
       " 'VE_05',\n",
       " 'QA_06',\n",
       " 'VA_06',\n",
       " 'QC_06',\n",
       " 'VC_06',\n",
       " 'QE_06',\n",
       " 'VE_06',\n",
       " 'QA_07',\n",
       " 'VA_07',\n",
       " 'QC_07',\n",
       " 'VC_07',\n",
       " 'QE_07',\n",
       " 'VE_07',\n",
       " 'QA_08',\n",
       " 'VA_08',\n",
       " 'QC_08',\n",
       " 'VC_08',\n",
       " 'QE_08',\n",
       " 'VE_08',\n",
       " 'QA_09',\n",
       " 'VA_09',\n",
       " 'QC_09',\n",
       " 'VC_09',\n",
       " 'QE_09',\n",
       " 'VE_09',\n",
       " 'QA_10',\n",
       " 'VA_10',\n",
       " 'QC_10',\n",
       " 'VC_10',\n",
       " 'QE_10',\n",
       " 'VE_10',\n",
       " 'QA_11',\n",
       " 'VA_11',\n",
       " 'QC_11',\n",
       " 'VC_11',\n",
       " 'QE_11',\n",
       " 'VE_11',\n",
       " 'QA_12',\n",
       " 'VA_12',\n",
       " 'QC_12',\n",
       " 'VC_12',\n",
       " 'QE_12',\n",
       " 'VE_12',\n",
       " 'LakeFract',\n",
       " 'SurfArea',\n",
       " 'RAreaHLoad',\n",
       " 'RPUID',\n",
       " 'VPUID',\n",
       " 'Enabled']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "x = list(lines.columns)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}