{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597105503645",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing how to filter the error with Hydroseq, while keeping dam info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "hydroseq_dups1 = pd.read_csv('extracted_HUC1019.csv', usecols=['Hydroseq', 'UpHydroseq', 'DnHydroseq',\n",
    "                            'REACHCODE', 'LENGTHKM', \n",
    "                            'COMID', 'DamID', 'WKT', 'Norm_stor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Hydroseq  0\n0      550004049  1\n1      550004051  1\n2      550004052  1\n3      550004054  1\n4      550004056  1\n...          ... ..\n14842  550202355  1\n14843  550202356  1\n14844  550202357  1\n14845  550202358  1\n14846  550202359  1\n\n[14847 rows x 2 columns]\n"
    }
   ],
   "source": [
    "#Keep only the last Hydroseq\n",
    "hydroseq_dups = hydroseq_dups1.drop_duplicates(subset='Hydroseq', keep=\"last\")  #drop everything but last duplicate\n",
    "test_df = hydroseq_dups.drop(columns=['Norm_stor'])  #drop Norm_stor\n",
    "#Group by hydroseq and sum the storage\n",
    "test_stor = hydroseq_dups.groupby(['Hydroseq'])['Norm_stor'].sum().reset_index()\n",
    "#Count # of duplicate dams\n",
    "hydroseq_dups1['DamCount'] = np.zeros(len(hydroseq_dups1))\n",
    "count_df = hydroseq_dups1.pivot_table(index=['Hydroseq'], aggfunc='size').reset_index()\n",
    "#Merge the dataframes so the storage and DamIDs are how we want\n",
    "merged = test_df.merge(test_stor, how= 'left', on='Hydroseq') # Merge NABD and NHD\n",
    "# m = count_df[count_df.Hydroseq==550027928]\n",
    "print(count_df)\n",
    "# print(m)\n",
    "# print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "COMID  Norm_stor   DamID  \\\n87   2889298.0    11234.0  3816.0   \n88   2889298.0    11234.0  3817.0   \n101  2891624.0    41811.0  3832.0   \n102  2891624.0    41000.0  4313.0   \n146  5241412.0      130.0  3883.0   \n147  5241412.0       41.0  4370.0   \n71   2885282.0       30.0  3798.0   \n72   2885282.0      257.0  3799.0   \n189   228551.0       19.0  4264.0   \n190   228551.0       38.0  4265.0   \n191   228551.0       99.0  4266.0   \n192   228551.0       14.3  4422.0   \n\n                                                   WKT  LENGTHKM  REACHCODE  \\\n87   MULTILINESTRING ZM ((-105.182906280508 40.0301...     5.134     1019.0   \n88   MULTILINESTRING ZM ((-105.182906280508 40.0301...     5.134     1019.0   \n101  MULTILINESTRING ZM ((-105.358636280236 39.9485...     0.085     1019.0   \n102  MULTILINESTRING ZM ((-105.358636280236 39.9485...     0.085     1019.0   \n146  MULTILINESTRING ZM ((-105.396787280176 38.9059...     1.432     1019.0   \n147  MULTILINESTRING ZM ((-105.396787280176 38.9059...     1.432     1019.0   \n71   MULTILINESTRING ZM ((-105.432013813455 39.6939...     2.746     1019.0   \n72   MULTILINESTRING ZM ((-105.432013813455 39.6939...     2.746     1019.0   \n189  MULTILINESTRING ZM ((-105.224265880444 39.8914...     6.118     1019.0   \n190  MULTILINESTRING ZM ((-105.224265880444 39.8914...     6.118     1019.0   \n191  MULTILINESTRING ZM ((-105.224265880444 39.8914...     6.118     1019.0   \n192  MULTILINESTRING ZM ((-105.224265880444 39.8914...     6.118     1019.0   \n\n      Hydroseq  UpHydroseq  DnHydroseq  \n87   550027928   550028248   550024978  \n88   550027928   550028248   550024978  \n101  550035223   550035943   550034557  \n102  550035223   550035943   550034557  \n146  550096097   550119344   550082427  \n147  550096097   550119344   550082427  \n71   550099115   550124584   550084390  \n72   550099115   550124584   550084390  \n189  550201408           0   550126139  \n190  550201408           0   550126139  \n191  550201408           0   550126139  \n192  550201408           0   550126139  \n"
    }
   ],
   "source": [
    "Hduplicates = pd.concat(g for _, g in seq_dup.groupby(\"Hydroseq\") if len(g) > 1)  #group duplicates together\n",
    "# flowlines = flowlines.drop_duplicates(subset='Hydroseq', keep=\"last\")  #drop everything but last duplicate\n",
    "print(Hduplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "gdrive = Path(\"/Volumes/GoogleDrive/My Drive/Condon_Research_Group/Research_Projects/Rachel/Research/GIS/Layers\") #where shapefiles/csv live \n",
    "\n",
    "nabd = pd.DataFrame()\n",
    "def extract_dams(nabd):\n",
    "    ## NABD\n",
    "    nabd = gp.read_file(gdrive/\"nabd_fish_barriers_2012.shp\")  #read in NABD from Drive\n",
    "    nabd = nabd.drop_duplicates(subset='NIDID', keep=\"first\")  #drop everything after first duplicate\n",
    "    nabd[\"DamID\"] = range(len(nabd.COMID))  #add DamID \n",
    "    # print(nabd.DamID.unique)  #check the DamIDs\n",
    "    return nabd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "COMMENT    NIDID        COMID UNIQUE_STR        newX       newY  \\\n0           1  AL00288     893441.0          1  -86.196373  31.424403   \n1           1  AL01925     894119.0          2  -86.400374  31.170262   \n2           1  AL00648     895019.0          3  -86.299755  31.223052   \n3           1  AL00652     895035.0          4  -86.450075  31.179562   \n4           1  AL00641     895041.0          5  -86.346634  31.143277   \n...       ...      ...          ...        ...         ...        ...   \n52451       1  AK00189   41700279.0      52561 -149.551141  61.348327   \n52452       1  AK00029   41701413.0      52562 -149.924029  61.207976   \n52453       1  AK00060   62834739.0      52563 -149.457555  60.102455   \n52454       1  AK00019   62833387.0      52564 -148.077985  60.048443   \n52455       1  AK00207  125387387.0      52565 -152.455619  57.920862   \n\n       RecordID              Dam_name Dam_former     STATEID  ... Num_locks  \\\n0         326.0    DONALDSON LAKE DAM       None        None  ...       0.0   \n1        1679.0  CHARLES WOODHAM LAKE       None        None  ...       0.0   \n2         641.0           JERRY ADAMS       None        None  ...       0.0   \n3         642.0        CLIFTON MADDOX       None  AL36100004  ...       0.0   \n4         638.0          JAMES CRAVEY       None        None  ...       0.0   \n...         ...                   ...        ...         ...  ...       ...   \n52451       0.0                  None       None        None  ...       0.0   \n52452       0.0                  None       None        None  ...       0.0   \n52453       0.0                  None       None        None  ...       0.0   \n52454       0.0                  None       None        None  ...       0.0   \n52455       0.0                  None       None        None  ...       0.0   \n\n      Len_locks Wid_locks Source  Condition Cond_Date Cond_desc Spill_wid  \\\n0           0.0       0.0     AL       None      None      None       0.0   \n1           0.0       0.0     AL       None      None      None       0.0   \n2           0.0       0.0     AL       None      None      None       0.0   \n3           0.0       0.0     AL       None      None      None      65.0   \n4           0.0       0.0     AL       None      None      None       0.0   \n...         ...       ...    ...        ...       ...       ...       ...   \n52451       0.0       0.0   None       None      None      None       0.0   \n52452       0.0       0.0   None       None      None      None       0.0   \n52453       0.0       0.0   None       None      None      None       0.0   \n52454       0.0       0.0   None       None      None      None       0.0   \n52455       0.0       0.0   None       None      None      None       0.0   \n\n                          geometry  DamID  \n0       POINT (-86.19637 31.42440)      0  \n1       POINT (-86.40037 31.17026)      1  \n2       POINT (-86.29975 31.22305)      2  \n3       POINT (-86.45007 31.17956)      3  \n4       POINT (-86.34663 31.14328)      4  \n...                            ...    ...  \n52451  POINT (-149.55114 61.34833)  51790  \n52452  POINT (-149.92403 61.20798)  51791  \n52453  POINT (-149.45755 60.10245)  51792  \n52454  POINT (-148.07799 60.04844)  51793  \n52455  POINT (-152.45562 57.92086)  51794  \n\n[51795 rows x 57 columns]\n"
    }
   ],
   "source": [
    "print(extract_dams(nabd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function():\n",
    "  print(\"Hello from a very nice function\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Hello from a very nice function\nNone\n"
    }
   ],
   "source": [
    "print(my_function())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}