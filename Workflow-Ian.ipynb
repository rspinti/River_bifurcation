{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# River bifurcation in CONUS workflow\n",
    "This notebook contains the workflow necessary to extract data from a HUC4 and join it to NABD for bifurcation analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic analysis \n",
    "from pathlib import Path\n",
    "import os\n",
    "from time import time\n",
    "import geopandas as gp\n",
    "\n",
    "\n",
    "# import extract module for analysis\n",
    "from extract_nhd import extract_nhdflowlines  # this function was created by Rachel to extract info from other NHD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial setup and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select HUC of interest\n",
    "HUC2 = 10\n",
    "i = 19\n",
    "HUC4 = \"{0}{1:02d}\".format(HUC2, i)  # this formats the HUC4 name how we want it. ':02d' is string formatting\n",
    "# print(HUC4)\n",
    "# print(type(HUC4))\n",
    "huc_id = int(HUC4) * 1000000   # the full HUC4 ID\n",
    "# print(huc_id)\n",
    "\n",
    "# Setting projections\n",
    "CRS = {           # Using USGS CONUS Albers (EPSG:102003): https://epsg.io/102003  WHY?\n",
    "    \"proj\": \"aea\",\n",
    "    \"lat_1\": 29.5,\n",
    "    \"lat_2\": 45.5,\n",
    "    \"lat_0\": 37.5,\n",
    "    \"lon_0\": -96,\n",
    "    \"x_0\": 0,\n",
    "    \"y_0\": 0,\n",
    "    \"datum\": \"NAD83\",\n",
    "    \"units\": \"m\",\n",
    "    \"no_defs\": True,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read in the geodatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = Path(\"/Volumes/GoogleDrive/My Drive/Condon_Research_Group/Research_Projects/Rachel/Research/GIS/Layers/NHDPlusNationalData\")  # point to where GDBs are\n",
    "\n",
    "# # Read in the entire gdb from Drive\n",
    "# gdb = data_dir/\"NHDPlusV21_National_Seamless_Flattened_Lower48.gdb\"\n",
    "# print(gdb)\n",
    "# read_start = time()\n",
    "# flowlines = extract_nhdflowlines(gdb, target_crs=CRS)\n",
    "# print(\"Read {:,} flowlines in  {:.0f} seconds\".format(len(flowlines), time() - read_start))\n",
    "\n",
    "# # Filter the gdb as it is read in\n",
    "# gdb = data_dir/ \"NHDPlusV21_National_Seamless_Flattened_Lower48.gdb\".format(HUC4=HUC4)\n",
    "# print(gdb)\n",
    "# read_start = time()\n",
    "# flowlines, joins = extract_nhdflowlines(gdb, target_crs=CRS)\n",
    "# print(\"Read {:,} flowlines in  {:.0f} seconds\".format(len(flowlines), time() - read_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/Users/rachelspinti/Documents/River_bifurcation/data/nhd/NHDPlusNationalData\")  # point to where GDBs are\n",
    "\n",
    "# nhd_gdb = gp.read_file(data_dir/\"NHDPlusV21_National_Seamless_Flattened_Lower48.gdb\")\n",
    "gdb_path = data_dir/\"NHDPlusV21_National_Seamless_Flattened_Lower48.gdb\"\n",
    "# cats = gp.read_file(gdb_path, layer=\"Catchment\")\n",
    "# flowline_cols = [\"COMID\", \"NHDPlusID\", \"FlowDir\", \"FType\", \"geometry\", \"ReachCode\"]\n",
    "flowlines = gp.read_file(gdb_path, layer=\"NHDFlowline_Network\")[3]\n",
    "# flowlines = gp.read_file(gdb_path, layer=\"NHDFlowline_Network\")[flowline_cols]\n",
    "\n",
    "\n",
    "# # Read in the entire gdb\n",
    "# gdb = data_dir/\"NHDPlusV21_National_Seamless_Flattened_Lower48.gdb\"\n",
    "# print(gdb)\n",
    "# read_start = time()\n",
    "# flowlines = extract_nhdflowlines(gdb, target_crs=CRS)\n",
    "# print(\"Read {:,} flowlines in  {:.0f} seconds\".format(len(flowlines), time() - read_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nhd_gdb.head(3)\n",
    "flowlines.head(3)\n",
    "# print(len(flowlines))\n",
    "# cats.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "import pandas as pd\n",
    "data = {'HUC':  [101901, 102002, 101902, 101510]}\n",
    "\n",
    "df = pd.DataFrame (data, columns = ['HUC'])\n",
    "\n",
    "huc4 = 1019\n",
    "select = data['HUC'][:3] == huc4\n",
    "print(select)\n",
    "# int(str(number)[:2])\n",
    "# gapminder['year']==2002\n",
    "print(data['HUC'] == )\n",
    "\n",
    "select_index = data['HUC'].str.contains('huc4')\n",
    "select = data[select_index]\n",
    "select"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
