{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# River bifurcation in CONUS workflow\n",
    "This notebook contains the workflow necessary to extract data from a HUC4 and join it to NABD for bifurcation analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic analysis \n",
    "from pathlib import Path\n",
    "import os\n",
    "from time import time\n",
    "import geopandas as gp\n",
    "\n",
    "\n",
    "# import extract module for analysis\n",
    "from extract_nhd import extract_nhdflowlines  # this function was created by Rachel to extract info from other NHD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial setup and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select HUC of interest\n",
    "HUC2 = 10\n",
    "i = 19\n",
    "HUC4 = \"{0}{1:02d}\".format(HUC2, i)  # this formats the HUC4 name how we want it. ':02d' is string formatting\n",
    "# print(HUC4)\n",
    "# print(type(HUC4))\n",
    "huc_id = int(HUC4) * 1000000   # the full HUC4 ID\n",
    "# print(huc_id)\n",
    "\n",
    "# Setting projections\n",
    "CRS = {           # Using USGS CONUS Albers (EPSG:102003): https://epsg.io/102003  WHY?\n",
    "    \"proj\": \"aea\",\n",
    "    \"lat_1\": 29.5,\n",
    "    \"lat_2\": 45.5,\n",
    "    \"lat_0\": 37.5,\n",
    "    \"lon_0\": -96,\n",
    "    \"x_0\": 0,\n",
    "    \"y_0\": 0,\n",
    "    \"datum\": \"NAD83\",\n",
    "    \"units\": \"m\",\n",
    "    \"no_defs\": True,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read in the geodatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/Volumes/GoogleDrive/My Drive/Condon_Research_Group/Research_Projects/Rachel/Research/GIS/Layers/NHDPlusNationalData\")  # point to where GDBs are\n",
    "\n",
    "# # Read in the entire gdb from Drive\n",
    "# gdb = data_dir/\"NHDPlusV21_National_Seamless_Flattened_Lower48.gdb\"\n",
    "# print(gdb)\n",
    "# read_start = time()\n",
    "# flowlines = extract_nhdflowlines(gdb, target_crs=CRS)\n",
    "# print(\"Read {:,} flowlines in  {:.0f} seconds\".format(len(flowlines), time() - read_start))\n",
    "\n",
    "# Filter the gdb as it is read in\n",
    "gdb = data_dir/ \"NHDPlusV21_National_Seamless_Flattened_Lower48.gdb\".format(HUC4=HUC4)\n",
    "print(gdb)\n",
    "read_start = time()\n",
    "flowlines, joins = extract_nhdflowlines(gdb, target_crs=CRS)\n",
    "print(\"Read {:,} flowlines in  {:.0f} seconds\".format(len(flowlines), time() - read_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
